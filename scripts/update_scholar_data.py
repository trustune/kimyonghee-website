#!/usr/bin/env python3
"""
Google Scholar í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸
ë…¼ë¬¸ ì œëª©, ì¸ìš© ìˆ˜, ì—°ë„, abstract ë“±ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ publications.json ì—…ë°ì´íŠ¸
"""

import json
import re
import time
from pathlib import Path

def install_scholarly():
    """scholarly ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"""
    import subprocess
    try:
        import scholarly
        print("âœ“ scholarly ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    except ImportError:
        print("scholarly ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤...")
        subprocess.check_call(["pip", "install", "scholarly"])
        print("âœ“ scholarly ì„¤ì¹˜ ì™„ë£Œ")

def get_scholar_data(author_id="semkeskAAAAJ"):
    """Google Scholarì—ì„œ ì €ì ì •ë³´ ë° ë…¼ë¬¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    from scholarly import scholarly

    print(f"\nğŸ“š Google Scholar í”„ë¡œí•„ ê²€ìƒ‰ ì¤‘: {author_id}")

    try:
        # ì €ì í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸°
        search_query = scholarly.search_author_id(author_id)
        author = scholarly.fill(search_query)

        print(f"âœ“ ì €ì: {author.get('name', 'Unknown')}")
        print(f"âœ“ ì†Œì†: {author.get('affiliation', 'Unknown')}")

        # í†µê³„ ì •ë³´
        stats = {
            'citations': author.get('citedby', 0),
            'hIndex': author.get('hindex', 0),
            'i10Index': author.get('i10index', 0),
        }

        print(f"\nğŸ“Š í†µê³„:")
        print(f"  - Citations: {stats['citations']}")
        print(f"  - h-index: {stats['hIndex']}")
        print(f"  - i10-index: {stats['i10Index']}")

        # ë…¼ë¬¸ ëª©ë¡
        publications = []
        print(f"\nğŸ“„ ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")

        for idx, pub in enumerate(author.get('publications', []), 1):
            try:
                # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ëŠë¦´ ìˆ˜ ìˆìŒ)
                pub_filled = scholarly.fill(pub)

                pub_data = {
                    'title': pub_filled.get('bib', {}).get('title', ''),
                    'authors': pub_filled.get('bib', {}).get('author', '').split(' and '),
                    'journal': pub_filled.get('bib', {}).get('venue', ''),
                    'year': int(pub_filled.get('bib', {}).get('pub_year', 0)) if pub_filled.get('bib', {}).get('pub_year') else None,
                    'citations': pub_filled.get('num_citations', 0),
                    'abstract': pub_filled.get('bib', {}).get('abstract', ''),
                    'pub_url': pub_filled.get('pub_url', ''),
                    'eprint_url': pub_filled.get('eprint_url', ''),
                }

                publications.append(pub_data)
                print(f"  {idx}. {pub_data['title'][:60]}... ({pub_data['citations']} citations)")

                # Google Scholar ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—°
                time.sleep(2)

            except Exception as e:
                print(f"  âš  ë…¼ë¬¸ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue

        print(f"\nâœ“ ì´ {len(publications)}ê°œ ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")

        # ì¸ìš© ê·¸ë˜í”„ ë°ì´í„° ìˆ˜ì§‘
        citation_graph = []
        try:
            cites_per_year = author.get('cites_per_year', {})
            if cites_per_year:
                for year, count in sorted(cites_per_year.items()):
                    citation_graph.append({'year': int(year), 'citations': count})
                print(f"\nğŸ“Š ì¸ìš© ê·¸ë˜í”„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({len(citation_graph)}ê°œ ì—°ë„)")
        except Exception as e:
            print(f"âš  ì¸ìš© ê·¸ë˜í”„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        return {
            'stats': stats,
            'publications': publications,
            'citation_graph': citation_graph
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def match_and_update_publications(scholar_data, json_path):
    """
    í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ê¸°ì¡´ publications.jsonê³¼ ë§¤ì¹­í•˜ì—¬ ì—…ë°ì´íŠ¸
    """
    print(f"\nğŸ“ publications.json ì—…ë°ì´íŠ¸ ì¤‘...")

    # ê¸°ì¡´ JSON ì½ê¸°
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    existing_pubs = data.get('publications', [])
    scholar_pubs = scholar_data['publications']

    updated_count = 0

    for existing_pub in existing_pubs:
        existing_title = existing_pub.get('title', '').lower().strip()

        # Scholar ë°ì´í„°ì—ì„œ ë§¤ì¹­ë˜ëŠ” ë…¼ë¬¸ ì°¾ê¸° (ì œëª© ìœ ì‚¬ë„ ê¸°ë°˜)
        for scholar_pub in scholar_pubs:
            scholar_title = scholar_pub.get('title', '').lower().strip()

            # ì œëª©ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë§¤ì¹­ìœ¼ë¡œ ê°„ì£¼
            if existing_title in scholar_title or scholar_title in existing_title:
                # ì¸ìš© ìˆ˜ ì—…ë°ì´íŠ¸
                existing_pub['citations'] = scholar_pub['citations']

                # abstractê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                if not existing_pub.get('abstract') and scholar_pub.get('abstract'):
                    # abstractë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ì¶•ì•½
                    abstract_sentences = scholar_pub['abstract'].split('. ')[:2]
                    existing_pub['abstract'] = '. '.join(abstract_sentences).strip()
                    if not existing_pub['abstract'].endswith('.'):
                        existing_pub['abstract'] += '.'

                # PDF URL ì—…ë°ì´íŠ¸
                if scholar_pub.get('eprint_url') and not existing_pub.get('pdf'):
                    existing_pub['pdf'] = scholar_pub['eprint_url']

                # status ì—…ë°ì´íŠ¸
                if not existing_pub.get('status'):
                    existing_pub['status'] = 'published'

                updated_count += 1
                print(f"  âœ“ ì—…ë°ì´íŠ¸: {existing_pub['title'][:60]}... ({existing_pub['citations']} citations)")
                break

    # Scholar í†µê³„ì™€ ê·¸ë˜í”„ ë°ì´í„° ì¶”ê°€
    data['scholarStats'] = scholar_data['stats']
    data['citationGraph'] = scholar_data.get('citation_graph', [])

    # JSON ì €ì¥
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… {updated_count}ê°œ ë…¼ë¬¸ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print(f"âœ… Scholar í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {json_path}")

    return updated_count, data.get('publications', [])


def update_md_files(publications, md_dir):
    """
    publications.jsonì˜ citations ë°ì´í„°ë¥¼ .md íŒŒì¼ì—ë„ ë™ê¸°í™”
    """
    print(f"\nğŸ“ Markdown íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘...")

    updated_count = 0

    for pub in publications:
        pub_id = pub.get('id', '')
        citations = pub.get('citations', 0)

        if not pub_id:
            continue

        md_file = md_dir / f"{pub_id}.md"

        if not md_file.exists():
            continue

        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # frontmatterì—ì„œ citations ê°’ ì°¾ê¸° ë° ì—…ë°ì´íŠ¸
            pattern = r'^(citations:\s*)(\d+)(.*)$'
            new_content = re.sub(
                pattern,
                f'\\g<1>{citations}\\g<3>',
                content,
                flags=re.MULTILINE
            )

            if new_content != content:
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                updated_count += 1
                print(f"  âœ“ {pub_id}.md ì—…ë°ì´íŠ¸ ({citations} citations)")

        except Exception as e:
            print(f"  âš  {pub_id}.md ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    print(f"\nâœ… {updated_count}ê°œ Markdown íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    return updated_count

def update_scholar_stats(scholar_data, astro_file_path):
    """
    publications.astro íŒŒì¼ì˜ Scholar í†µê³„ ìë™ ì—…ë°ì´íŠ¸
    """
    print(f"\nğŸ“Š publications.astroì˜ í†µê³„ ì—…ë°ì´íŠ¸ ì¤‘...")

    with open(astro_file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    stats = scholar_data['stats']

    # í†µê³„ ì„¹ì…˜ ì°¾ê¸° ë° êµì²´
    import re

    pattern = r'const scholarStats = \{[^}]+\};'

    new_stats = f"""const scholarStats = {{
  citations: {stats['citations']},
  citationsSince2020: 957,  // ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš”
  hIndex: {stats['hIndex']},
  hIndexSince2020: 6,  // ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš”
  i10Index: {stats['i10Index']},
  i10IndexSince2020: 5,  // ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš”
  lastUpdated: "November 2025"
}};"""

    content = re.sub(pattern, new_stats, content)

    with open(astro_file_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print(f"âœ… í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print(f"  - Citations: {stats['citations']}")
    print(f"  - h-index: {stats['hIndex']}")
    print(f"  - i10-index: {stats['i10Index']}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("Google Scholar í¬ë¡¤ë§ ë° ë°ì´í„° ì—…ë°ì´íŠ¸")
    print("=" * 60)

    # scholarly ì„¤ì¹˜ í™•ì¸
    install_scholarly()

    # í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
    project_root = Path(__file__).parent.parent
    json_path = project_root / 'src' / 'data' / 'publications.json'
    md_dir = project_root / 'src' / 'content' / 'publications'
    astro_path = project_root / 'src' / 'pages' / 'research' / 'publications.astro'

    print(f"\nğŸ“‚ í”„ë¡œì íŠ¸ ê²½ë¡œ: {project_root}")
    print(f"ğŸ“‚ JSON ê²½ë¡œ: {json_path}")
    print(f"ğŸ“‚ MD ê²½ë¡œ: {md_dir}")

    # Google Scholar ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    scholar_data = get_scholar_data("semkeskAAAAJ")

    if not scholar_data:
        print("\nâŒ Scholar ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    # publications.json ì—…ë°ì´íŠ¸
    _, publications = match_and_update_publications(scholar_data, json_path)

    # .md íŒŒì¼ citations ë™ê¸°í™”
    update_md_files(publications, md_dir)

    # publications.astro í†µê³„ ì—…ë°ì´íŠ¸
    # update_scholar_stats(scholar_data, astro_path)

    print("\n" + "=" * 60)
    print("âœ… ëª¨ë“  ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  1. src/data/publications.json í™•ì¸")
    print("  2. npm run build")
    print("  3. cp -r dist/* /var/www/kimyonghee.com/public/")

if __name__ == "__main__":
    main()
